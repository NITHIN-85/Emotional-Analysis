ü§ì Kannada Text Emotion Analysis

üìñ Overview

Emotional-Analysis is a machine learning project focused on detecting and classifying emotions in Kannada language text. It uses deep learning models (BERT + LSTM) and custom preprocessing techniques to analyze sentences and predict emotional states such as Joy, Neutral, Fear, Anger, Sadness, Disgust, and Surprise. The project is designed to handle inputs with mixed emotions and provides detailed output on the detected emotional content.

üöÄ Features

Emotion Detection Model : Utilizes BERT embeddings with an LSTM classifier to predict emotions from Kannada text.

Custom Preprocessing : Cleans and tokenizes input sentences, splitting on delimiters like ".", "‡≤Ü‡≤¶‡≤∞‡≥Ü", "‡≤Æ‡≤§‡≥ç‡≤§‡≥Å" for fine-grained analysis.

Weighted Emotion Mapping : Assigns weights to specific emotion keywords in Kannada for more accurate classification.

Mixed Emotion Handling : Capable of detecting and reporting multiple emotions in a single sentence.

Dataset Handling : Includes code for loading, preprocessing, encoding, and splitting datasets for training and testing.

Evaluation Metrics : Calculates accuracy using labeled test data and saves predictions to Excel for further analysis.

üõ†Ô∏è Tech Stack

- Python 3.x
- PyTorch
- Transformers (HuggingFace)
- Pandas
- scikit-learn

üìä Dataset Information

Prepare your dataset in CSV/Excel format with the following columns:

- `Sentence`: The Kannada text to analyze.
- `Emotion`: The labeled emotion for supervised training.

Example:

| Sentence                                       | Emotion  |
|------------------------------------------------|----------|
| ‡≤ú‡≤®‡≤∞‡≥Å ‡≤á‡≤§‡≤∞‡≤∞ ‡≤ï‡≤°‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤®‡≥Å‡≤≠‡≥Ç‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤¶‡≤∞‡≥ç‡≤∂‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≤®‡≥ç‡≤®‡≥Å ... | Joy      |
| ‡≤®‡≤ó‡≤∞‡≤µ‡≥Å ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø‡≤® ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤∏‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤ï‡≥á‡≤Ç‡≤¶‡≥ç‡≤∞‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤í‡≤Ç‡≤¶‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü | Neutral  |

Training the Model

Run `BERT_LSTM.ipynb` to:

- Load and preprocess the data.
- Encode sentences and emotions.
- Split into train/validation sets.
- Train the BERT + LSTM model.
- Evaluate accuracy on a test set.

 Predicting Emotions

Use the function in `test.ipynb`:

```python
sentence = "‡≤∞‡≤æ‡≤§‡≥ç‡≤∞‡≤ø ‡≤π‡≥ä‡≤∞‡≤ó‡≥Ü ‡≤π‡≥ã‡≤ó‡≥Å‡≤µ‡≥Å‡≤¶‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤®‡≤®‡≤ó‡≥Ü ‡≤¨‡≤π‡≤≥ Fear. ‡≤Ü‡≤¶‡≤∞‡≥Ü ‡≤®‡≤®‡≥ç‡≤® ‡≤∏‡≥ç‡≤®‡≥á‡≤π‡≤ø‡≤§‡≤® ‡≤®‡≤ø‡≤∞‡≥ç‡≤≤‡≤ï‡≥ç‡≤∑‡≥ç‡≤Ø‡≤¶‡≤ø‡≤Ç‡≤¶ ‡≤®‡≤®‡≤ó‡≥Ü ‡≤ï‡≥ã‡≤™ ‡≤¨‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü."
predicted_label = predict_emotion(sentence)
print(f"Predicted Emotion Label: {predicted_label}")
```
Custom Keyword Mapping

The project uses a dictionary mapping Kannada emotion words to model labels and weights for fine-tuned predictions.

Example mapping:

python
{
    '‡≤â‡≤≤‡≥ç‡≤≤‡≤æ‡≤∏': {'label': 'joy', 'weight': 2.0},
    '‡≤≠‡≤Ø': {'label': 'fear', 'weight': 2.0},
    '‡≤ï‡≥ç‡≤∞‡≥ã‡≤ß': {'label': 'anger', 'weight': 2.0},
    '‡≤¶‡≥Å‡≤É‡≤ñ': {'label': 'sadness', 'weight': 2.0},
    '‡≤Ü‡≤∂‡≥ç‡≤ö‡≤∞‡≥ç‡≤Ø': {'label': 'surprise', 'weight': 2.0},
    # ... more mappings
}

‚úÖ How It Works
Data Preprocessing : Clean text, remove stopwords, tokenize, and vectorize using TF-IDF.

Model Training : Train SVM classifier on labeled emotion dataset.

Prediction & Evaluation : Predict emotions for new text and evaluate using confusion matrix, accuracy score.

Usage

- Train the model using your own dataset or the provided example.
- Test new sentences for emotion prediction.
- Analyze accuracy and results using the saved Excel output.

Acknowledgments
- Uses HuggingFace Transformers for BERT
- Developed for Kannada language NLP tasks

For more details and examples, refer to the Jupyter notebooks in the repository.
