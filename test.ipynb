{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "# Load the label encoder\n",
    "label_encoder = joblib.load('label_encoder.pkl')  # Replace with actual path to your saved label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_LSTM_EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=128, lstm_layers=1, bidirectional=True, dropout=0.3, word_weight_mapping=None, label_encoder=None):\n",
    "        super(BERT_LSTM_EmotionClassifier, self).__init__()\n",
    "\n",
    "        # Load the pre-trained BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, num_classes)\n",
    "\n",
    "        # Store the word weight mapping and label encoder\n",
    "        self.word_weight_mapping = word_weight_mapping if word_weight_mapping is not None else {}\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, sentences=None):\n",
    "        # Pass inputs through BERT\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "\n",
    "        # Pass BERT output through the LSTM\n",
    "        lstm_output, (h_n, c_n) = self.lstm(sequence_output)\n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            lstm_output = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        else:\n",
    "            lstm_output = h_n[-1]\n",
    "\n",
    "        # Apply dropout\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        # Pass through the fully connected layer for classification\n",
    "        logits = self.fc(lstm_output)\n",
    "\n",
    "        # If sentences are provided, apply custom weights\n",
    "        if sentences is not None:\n",
    "            logits = self.apply_word_weights(logits, sentences)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def apply_word_weights(self, logits, sentences):\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            for word, info in self.word_weight_mapping.items():\n",
    "                if word in sentence:\n",
    "                    emotion_label = info['label']\n",
    "                    weight = info['weight']\n",
    "\n",
    "                    # Map emotion label to its corresponding index\n",
    "                    emotion_index = self.label_encoder.transform([emotion_label])[0]\n",
    "\n",
    "                    # Apply the weight to the logits (consider adding rather than multiplying)\n",
    "                    logits[i, emotion_index] += weight\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([\n",
    "    'ನಾನು', 'ಅದು', 'ಅವರು', 'ಮತ್ತು', 'ಈ', 'ಇದು', 'ಎಂದು', 'ಆ', 'ಅದೇ', 'ಇದನ್ನು',\n",
    "    'ನಾವು', 'ಅದನ್ನು', 'ನಿನ್ನ', 'ನನಗೆ', 'ಅವನು', 'ಅವಳು', 'ನಿಮ್ಮ', 'ಅವಳ', 'ಅವನ',\n",
    "    'ನನ್ನ',  'ಮತ್ತು','ಅವರು','ಇಲ್ಲ','ನೀನು','ಹಾಗೂ','ಅವು','ಹಾಗೆ','ಅಲ್ಲಿ','ಇಲ್ಲಿ','ಇವು'\n",
    "])\n",
    "\n",
    "word_weight_mapping = {\n",
    "    'ಸಂತೋಷ': {'label': 'joy', 'weight': 2.0},\n",
    "    'ಹಾಸ್ಯ': {'label': 'joy', 'weight': 2.0},\n",
    "    'ಖುಷಿ': {'label': 'joy', 'weight': 2.0},\n",
    "    'ಉಲ್ಲಾಸ': {'label': 'joy', 'weight': 2.0},\n",
    "    'ನಗು': {'label': 'joy', 'weight': 2.0},\n",
    "    'ಭಯ': {'label': 'fear', 'weight': 2.0},\n",
    "    'ಅಂಜಿಕೆ': {'label': 'fear', 'weight': 2.0},\n",
    "    'ಹೆದರಿಕೆ': {'label': 'fear', 'weight': 2.0},\n",
    "    'ಕ್ರೋಧ': {'label': 'anger', 'weight': 2.0},\n",
    "    'ಸಿಟ್ಟು': {'label': 'anger', 'weight': 2.0},\n",
    "    'ಕೋಪ': {'label': 'anger', 'weight': 2.0},\n",
    "    'ದುಃಖ': {'label': 'sadness', 'weight': 2.0},\n",
    "    'ಬೇಸರ': {'label': 'sadness', 'weight': 2.0},\n",
    "    'ನಿರಾಸೆ': {'label': 'sadness', 'weight': 2.0},\n",
    "    'ಆಶ್ಚರ್ಯ': {'label': 'surprise', 'weight': 2.0},\n",
    "    'ಅಚ್ಚರಿ': {'label': 'surprise', 'weight': 2.0},\n",
    "    'ವಿಸ್ಮಯ': {'label': 'surprise', 'weight': 2.0},\n",
    "    'ಆಘಾತ': {'label': 'surprise', 'weight': 2.0},\n",
    "    'ಬೆರಗು': {'label': 'surprise', 'weight': 2.0},\n",
    "    'ಅಸಹ್ಯ': {'label': 'disgust', 'weight': 2.0},\n",
    "    'ದ್ವೇಷ': {'label': 'disgust', 'weight': 2.0},\n",
    "    'ದುರಾಸೆ': {'label': 'disgust', 'weight': 2.0},\n",
    "    'ತಿರಸ್ಕಾರ': {'label': 'disgust', 'weight': 2.0}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import re\n",
    "from langdetect import detect, DetectorFactory, LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0  # Ensures consistent language detection\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Detect the language of the entire text first\n",
    "        if detect(text) != \"kn\":\n",
    "            return \"\"  # Skip non-Kannada text entirely\n",
    "\n",
    "        # Remove punctuation and special characters (except Kannada script)\n",
    "        text = re.sub(r'[^\\w\\s\\u0C80-\\u0CFF]', '', text)\n",
    "\n",
    "        # Remove newline characters\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "\n",
    "        # Remove words containing numbers\n",
    "        text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "        # Split into words and filter English words\n",
    "        words = text.split()\n",
    "\n",
    "        # Handle Kannada negations\n",
    "        negation_words = ['ಇಲ್ಲ', 'ವಾಗಲಿಲ್ಲ', 'ಅಲ್ಲ']\n",
    "        for i, word in enumerate(words):\n",
    "            if i > 0 and any(neg in word for neg in negation_words):\n",
    "                final_words[-1] = \"NOT_\" + final_words[-1]\n",
    "            else:\n",
    "                final_words.append(word)\n",
    "\n",
    "        # Remove stopwords (you need to define your `stop_words` list)\n",
    "        final_words = [word for word in final_words if word not in stop_words]\n",
    "\n",
    "        return ' '.join(final_words)\n",
    "    except LangDetectException:\n",
    "        # Handle cases where language detection fails\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_LSTM_EmotionClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'best_model_1.pth'\n",
    "model = BERT_LSTM_EmotionClassifier(num_classes=7)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text, threshold=0.2):\n",
    "    delimiters = [\".\", \"ಆದರೆ\", \"ಮತ್ತು\"]\n",
    "    parts = re.split(\"|\".join(map(re.escape, delimiters)), text)\n",
    "    parts = [part.strip() for part in parts if part.strip()]\n",
    "    all_emotions = set()\n",
    "\n",
    "    for sentence in parts:\n",
    "        preprocessed_sentence = preprocess_text(sentence)\n",
    "        if not preprocessed_sentence:\n",
    "            continue  # Skip sentences not in Kannada\n",
    "\n",
    "        inputs = tokenizer(preprocessed_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask)\n",
    "            probabilities = torch.softmax(output, dim=1).squeeze()\n",
    "\n",
    "        emotion_labels = label_encoder.classes_\n",
    "        detected_emotions = [emotion_labels[idx] for idx, prob in enumerate(probabilities) if prob >= threshold]\n",
    "\n",
    "        if len(detected_emotions) > 1:\n",
    "            all_emotions.add(\"Mixed Emotion (\" + \", \".join(detected_emotions) + \")\")\n",
    "        elif detected_emotions:\n",
    "            all_emotions.add(detected_emotions[0])\n",
    "\n",
    "    if len(all_emotions) > 1:\n",
    "        return \"Mixed Emotion (\" + \", \".join(all_emotions) + \")\"\n",
    "    elif all_emotions:\n",
    "        return \"\".join(all_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion Label: Mixed Emotion (Disgust, Anger)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ರಾತ್ರಿ ಹೊರಗೆ ಹೋಗುವುದಕ್ಕೆ ನನಗೆ ಬಹಳ Fear. ಆದರೆ ನನ್ನ ಸ್ನೇಹಿತನ ನಿರ್ಲಕ್ಷ್ಯದಿಂದ ನನಗೆ ಕೋಪ ಬಂದಿದೆ.\"  \n",
    "predicted_label = predict_emotion(sentence)\n",
    "print(f\"Predicted Emotion Label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
